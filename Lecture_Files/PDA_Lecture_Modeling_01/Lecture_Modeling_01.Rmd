---
# title: "Lecture 03"
# author: "Kasthuri Kannan"
# date: "Sept 07, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<style>
body {
text-align: justify}
</style>

---

### Modeling fundamentals 01: Basic inference and linear modeling (Oct. 31, 2017)

---

#### Z-test and t-Test

We will first study basic ideas in statistical inference using our HANES data set.


```{r eval=TRUE, message=FALSE}
  # Load the package RCurl
  library(RCurl)
  # Import the HANES data set from GitHub; break the string into two for readability
  # (Please note this readability aspect very carefully)
  URL_text_1 <- "https://raw.githubusercontent.com/kannan-kasthuri/kannan-kasthuri.github.io"
  URL_text_2 <- "/master/Datasets/HANES/NYC_HANES_DIAB.csv"
  # Paste it to constitute a single URL 
  URL <- paste(URL_text_1,URL_text_2, sep="")
  HANES <- read.csv(text=getURL(URL))
  # Rename the GENDER factor for identification
  HANES$GENDER <- factor(HANES$GENDER, labels=c("M","F"))
  # Rename the AGEGROUP factor for identification
  HANES$AGEGROUP <- factor(HANES$AGEGROUP, labels=c("20-39","40-59","60+"))
  # Rename the HSQ_1 factor for identification
  HANES$HSQ_1 <- factor(HANES$HSQ_1, labels=c("Excellent","Very Good","Good", "Fair", "Poor"))
  # Rename the DX_DBTS as a factor
  HANES$DX_DBTS <- factor(HANES$DX_DBTS, labels=c("DIAB","DIAB NO_DX","NO DIAB"))
  # Omit all NA from the data frame
  HANES <- na.omit(HANES)
  # Observe the structure
  str(HANES)
  # Load the tidyverse library
  library(tidyverse)
```

Also, we need a package "rafalib" for these materials. So, lets go ahead and install that package, and load the library.

```{r eval=FALSE, message=FALSE, warning=TRUE, echo=TRUE}
  # Install rafaliab library
  install.packages("rafalib")
```

```{r eval=TRUE, message=FALSE, warning=TRUE, echo=TRUE}
  # Load rafalib library
  library(rafalib)
```


##### Z-test

According to central limit theorem, if $X$ and $Y$ are independent and identically distributed random variables that represents a population, with mean $\mu_{X}$ and $\mu_{Y}$, and standard deviation, $\sigma_{X}$ and $\sigma_{Y}$, respectively, then the ratio,

$$
R = \frac{\mu_{Y}-\mu_{X}}{\sqrt{\frac{\sigma_X^2}{N} + \frac{\sigma_Y^2}{N}}}
$$
approaches normal distribution centered at $0$ and standard deviation $1$ as $N$ becomes large. In general, we will not know this mean and standard deviation for the population but only for a random sample from the general population. In case $X$ and $Y$ are normally distributed, the approximation to the mean $\mu_{X}$ and $\mu_{Y}$ given by $\hat{X}$ and $\hat{Y}$ are also normally distributed, and so are their difference. Therefore, the ratio $\hat{R}$, described by,

$$
\hat{R} = \frac{\hat{Y}-\hat{X}}{\sqrt{\frac{\sigma_X^2}{N} + \frac{\sigma_Y^2}{N}}}
$$

can be used to compute p-values simply because we know the proportion of the distribution under any value. For example, only 7% of these values are larger than 1.8 (in absolute value)

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE, na.rm=FALSE}
  pnorm(-1.8) + (1 - pnorm(1.8))
```

```{r eval=TRUE, message=FALSE, warning=TRUE, echo=FALSE}
  pnorm(-1.8) + (1 - pnorm(1.8))
```

Thus, if we know:

1. the population is normally distributed,
2. the standard deviation of the population and 
3. the sample size is large,

we can use this approximation. This is known as $Z$-test.

Most of the times, these conditions are hardly met. For the first condition that the population being normally distributed, although in practice we may not know the population distribution, we can see how close the sample distribution is close to normal distribution by plotting _qq-plots_ in order to confirm that the distributions are relatively close to being normally distributed.

We will work with the blood hemoglobin variable, A1C. We will consider people without diabetes as control group, that represents the **sample random variable** $Y$ and people with diabetes as disease group - that represents the **sample random variable** $X$. 

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE, na.rm=FALSE}
  # Extract only the A1C variable for the control group 
  control <- filter(HANES, DX_DBTS == "NO DIAB") %>% select(A1C)
  # and the disease group
  disease <- filter(HANES, DX_DBTS == "DIAB") %>% select(A1C)
```

```{r eval=TRUE, message=FALSE, warning=TRUE, echo=FALSE}
  # Extract only the A1C variable for the control group 
  control <- filter(HANES, DX_DBTS == "NO DIAB") %>% select(A1C)
  # and the disease group
  disease <- filter(HANES, DX_DBTS == "DIAB") %>% select(A1C)
```

We can now make a qqplot for the control variable

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE, na.rm=FALSE}
  # Find the 1st and 3rd quartiles
  y <- quantile(unlist(control), c(0.25, 0.75))
  # Find the matching normal values on the x-axis
  x <- qnorm( c(0.25, 0.75))
  # Compute the line slope
  slope <- diff(y) / diff(x) 
  # Compute the line intercept
  int <- y[1] - slope * x[1]
  # Generate normal q-q plot
  ggplot() + aes(sample=unlist(control)) + stat_qq(distribution=qnorm) + 
        geom_abline(intercept=int, slope=slope) + ylab("Sample") +
        labs(title = "QQ Plot for Control Variable")
```


```{r eval=TRUE, message=FALSE, warning=TRUE, echo=FALSE}
  # Find the 1st and 3rd quartiles
  y <- quantile(unlist(control), c(0.25, 0.75))
  # Find the matching normal values on the x-axis
  x <- qnorm( c(0.25, 0.75))
  # Compute the line slope
  slope <- diff(y) / diff(x) 
  # Compute the line intercept
  int <- y[1] - slope * x[1]
  # Generate normal q-q plot
  ggplot() + aes(sample=unlist(control)) + stat_qq(distribution=qnorm) + 
        geom_abline(intercept=int, slope=slope) + ylab("Sample") +
        labs(title = "QQ Plot for Control Variable")
```

Similarly we can make a qqplot for the disease variable

```{r eval=FALSE, message=FALSE, warning=FALSE, echo=TRUE, na.rm=FALSE}
  # Find the 1st and 3rd quartiles
  y <- quantile(unlist(disease), c(0.25, 0.75))
  # Find the matching normal values on the x-axis
  x <- qnorm( c(0.25, 0.75))
  # Compute the line slope
  slope <- diff(y) / diff(x) 
  # Compute the line intercept
  int <- y[1] - slope * x[1]
  # Generate normal q-q plot
  ggplot() + aes(sample=unlist(disease)) + stat_qq(distribution=qnorm) + 
        geom_abline(intercept=int, slope=slope) + ylab("Sample") +
        labs(title = "QQ Plot for Disease Variable")
```


```{r eval=TRUE, message=FALSE, warning=TRUE, echo=FALSE}
  # Find the 1st and 3rd quartiles
  y <- quantile(unlist(disease), c(0.25, 0.75))
  # Find the matching normal values on the x-axis
  x <- qnorm( c(0.25, 0.75))
  # Compute the line slope
  slope <- diff(y) / diff(x) 
  # Compute the line intercept
  int <- y[1] - slope * x[1]
  # Generate normal q-q plot
  ggplot() + aes(sample=unlist(disease)) + stat_qq(distribution=qnorm) + 
        geom_abline(intercept=int, slope=slope) + ylab("Sample") +
        labs(title = "QQ Plot for Disease Variable")
```




---

#### Selected materials and references

[R for Data Science - Wrangle Part](http://r4ds.had.co.nz/wrangle-intro.html)

---